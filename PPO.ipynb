{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from PPO.ppo import PPO\n",
    "from A2C.a2c import A2C\n",
    "from A3C.a3c import A3C\n",
    "from DDQN.ddqn import DDQN\n",
    "from DDPG.ddpg import DDPG\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from utils.atari_environment import AtariEnvironment\n",
    "from utils.continuous_environments import Environment\n",
    "from utils.networks import get_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class attrdict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        dict.__init__(self, *args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = attrdict(gpu=True, env='CartPole-v1', type='PPO', is_atari=False, \n",
    "                consecutive_frames=4, render=True, n_threads=16, nb_episodes=2_000,\n",
    "               training_interval=30, batch_size=64, gather_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/danilo/Documents/danilo/Deep-RL-Keras/utils/networks.py:8: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/Documents/danilo/Deep-RL-Keras/utils/networks.py:10: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_session(get_session())\n",
    "summary_writer = tf.summary.FileWriter(args.type + \"/tensorboard_\" + args.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Initialization\n",
    "if(args.is_atari):\n",
    "    # Atari Environment Wrapper\n",
    "    env = AtariEnvironment(args)\n",
    "    state_dim = env.get_state_size()\n",
    "    action_dim = env.get_action_size()\n",
    "elif(args.type==\"DDPG\"):\n",
    "    # Continuous Environments Wrapper\n",
    "    env = Environment(gym.make(args.env), args.consecutive_frames)\n",
    "    env.reset()\n",
    "    state_dim = env.get_state_size()\n",
    "    action_space = gym.make(args.env).action_space\n",
    "    action_dim = action_space.high.shape[0]\n",
    "    act_range = action_space.high\n",
    "else:\n",
    "    # Standard Environments\n",
    "    env = Environment(gym.make(args.env), args.consecutive_frames)\n",
    "    env.reset()\n",
    "    state_dim = env.get_state_size()[0]\n",
    "    action_dim = gym.make(args.env).action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1521: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 17,410\n",
      "Trainable params: 17,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               640       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 17,281\n",
      "Trainable params: 17,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Pick algorithm to train\n",
    "if(args.type==\"DDQN\"):\n",
    "    algo = DDQN(action_dim, state_dim, args)\n",
    "elif(args.type==\"A2C\"):\n",
    "    algo = A2C(action_dim, state_dim, args.consecutive_frames)\n",
    "elif(args.type==\"PPO\"):\n",
    "    algo = PPO(action_dim, state_dim, args.consecutive_frames)\n",
    "elif(args.type==\"A3C\"):\n",
    "    algo = A3C(action_dim, state_dim, args.consecutive_frames, is_atari=args.is_atari)\n",
    "elif(args.type==\"DDPG\"):\n",
    "    algo = DDPG(action_dim, state_dim, act_range, args.consecutive_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  1\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/danilo/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Episode:  110\n",
      "Episode:  225\n",
      "Episode:  352\n",
      "Episode:  492\n",
      "Episode:  642\n",
      "Episode:  779\n",
      "Episode:  922\n",
      "Episode:  1059\n",
      "Episode:  1205\n",
      "Episode:  1358\n",
      "Episode:  1512\n",
      "Episode:  1671\n",
      "Episode:  1835\n",
      "Episode:  2006\n",
      "Episode:  2166\n",
      "Episode:  2333\n",
      "Episode:  2492\n",
      "Episode:  2664\n",
      "Episode:  2831\n",
      "Episode:  3000\n",
      "Episode:  3168\n",
      "Episode:  3330\n",
      "Episode:  3487\n",
      "Episode:  3648\n",
      "Episode:  3813\n",
      "Episode:  3968\n",
      "Episode:  4125\n",
      "Episode:  4284\n",
      "Episode:  4444\n",
      "Episode:  4595\n",
      "Episode:  4759\n",
      "Episode:  4926\n",
      "Episode:  5088\n",
      "Episode:  5254\n",
      "Episode:  5421\n",
      "Episode:  5591\n",
      "Episode:  5762\n",
      "Episode:  5931\n",
      "Episode:  6096\n",
      "Episode:  6265\n",
      "Episode:  6425\n",
      "Episode:  6591\n",
      "Episode:  6759\n",
      "Episode:  6923\n",
      "Episode:  7085\n",
      "Episode:  7249\n",
      "Episode:  7415\n",
      "Episode:  7582\n",
      "Episode:  7750\n",
      "Episode:  7914\n",
      "Episode:  8079\n",
      "Episode:  8238\n",
      "Episode:  8398\n",
      "Episode:  8554\n",
      "Episode:  8725\n",
      "Episode:  8889\n",
      "Episode:  9041\n",
      "Episode:  9204\n",
      "Episode:  9363\n",
      "Episode:  9522\n",
      "Episode:  9689\n",
      "Episode:  9853\n",
      "Episode:  10015\n",
      "Episode:  10179\n",
      "Episode:  10338\n",
      "Episode:  10486\n",
      "Episode:  10649\n",
      "Episode:  10810\n",
      "Episode:  10965\n",
      "Episode:  11125\n",
      "Episode:  11282\n",
      "Episode:  11435\n",
      "Episode:  11589\n",
      "Episode:  11745\n",
      "Episode:  11903\n",
      "Episode:  12051\n",
      "Episode:  12203\n",
      "Episode:  12352\n",
      "Episode:  12500\n",
      "Episode:  12660\n",
      "Episode:  12818\n",
      "Episode:  12967\n",
      "Episode:  13119\n",
      "Episode:  13265\n",
      "Episode:  13414\n",
      "Episode:  13563\n",
      "Episode:  13718\n",
      "Episode:  13868\n",
      "Episode:  14020\n",
      "Episode:  14162\n",
      "Episode:  14313\n",
      "Episode:  14459\n",
      "Episode:  14595\n",
      "Episode:  14748\n",
      "Episode:  14888\n",
      "Episode:  15035\n",
      "Episode:  15181\n",
      "Episode:  15316\n",
      "Episode:  15456\n",
      "Episode:  15596\n",
      "Episode:  15723\n",
      "Episode:  15866\n",
      "Episode:  15995\n",
      "Episode:  16133\n",
      "Episode:  16264\n",
      "Episode:  16388\n",
      "Episode:  16520\n",
      "Episode:  16654\n",
      "Episode:  16794\n",
      "Episode:  16922\n",
      "Episode:  17054\n",
      "Episode:  17180\n",
      "Episode:  17312\n",
      "Episode:  17439\n",
      "Episode:  17565\n",
      "Episode:  17692\n",
      "Episode:  17814\n",
      "Episode:  17936\n",
      "Episode:  18058\n",
      "Episode:  18176\n",
      "Episode:  18304\n",
      "Episode:  18430\n",
      "Episode:  18555\n",
      "Episode:  18675\n",
      "Episode:  18793\n",
      "Episode:  18918\n",
      "Episode:  19034\n",
      "Episode:  19150\n",
      "Episode:  19269\n",
      "Episode:  19372\n",
      "Episode:  19469\n",
      "Episode:  19558\n",
      "Episode:  19645\n",
      "Episode:  19733\n",
      "Episode:  19825\n",
      "Episode:  19911\n",
      "Episode:  19997\n",
      "Episode:  20083\n",
      "Episode:  20155\n",
      "Episode:  20217\n",
      "Episode:  20263\n",
      "Episode:  20309\n",
      "Episode:  20356\n",
      "Episode:  20396\n",
      "Episode:  20437\n",
      "Episode:  20469\n",
      "Episode:  20502\n",
      "Episode:  20529\n",
      "Episode:  20548\n",
      "Episode:  20568\n",
      "Episode:  20589\n",
      "Episode:  20613\n",
      "Episode:  20640\n",
      "Episode:  20666\n",
      "Episode:  20693\n",
      "Episode:  20721\n",
      "Episode:  20749\n",
      "Episode:  20779\n",
      "Episode:  20809\n",
      "Episode:  20840\n",
      "Episode:  20871\n",
      "Episode:  20905\n",
      "Episode:  20933\n",
      "Episode:  20961\n",
      "Episode:  20987\n",
      "Episode:  21016\n",
      "Episode:  21043\n",
      "Episode:  21074\n",
      "Episode:  21104\n",
      "Episode:  21133\n",
      "Episode:  21159\n",
      "Episode:  21188\n",
      "Episode:  21210\n",
      "Episode:  21237\n",
      "Episode:  21257\n",
      "Episode:  21274\n",
      "Episode:  21292\n",
      "Episode:  21307\n",
      "Episode:  21324\n",
      "Episode:  21340\n",
      "Episode:  21355\n",
      "Episode:  21371\n",
      "Episode:  21387\n",
      "Episode:  21403\n",
      "Episode:  21417\n",
      "Episode:  21432\n",
      "Episode:  21444\n",
      "Episode:  21457\n",
      "Episode:  21470\n",
      "Episode:  21483\n",
      "Episode:  21496\n",
      "Episode:  21511\n",
      "Episode:  21524\n",
      "Episode:  21535\n",
      "Episode:  21547\n",
      "Episode:  21558\n",
      "Episode:  21570\n",
      "Episode:  21582\n",
      "Episode:  21594\n",
      "Episode:  21606\n",
      "Episode:  21619\n",
      "Episode:  21633\n",
      "Episode:  21646\n",
      "Episode:  21658\n",
      "Episode:  21670\n",
      "Episode:  21681\n",
      "Episode:  21693\n",
      "Episode:  21707\n",
      "Episode:  21721\n",
      "Episode:  21734\n",
      "Episode:  21747\n",
      "Episode:  21759\n",
      "Episode:  21770\n",
      "Episode:  21782\n",
      "Episode:  21793\n",
      "Episode:  21805\n",
      "Episode:  21815\n",
      "Episode:  21827\n",
      "Episode:  21838\n",
      "Episode:  21849\n",
      "Episode:  21859\n",
      "Episode:  21870\n",
      "Episode:  21878\n",
      "Episode:  21888\n",
      "Episode:  21897\n",
      "Episode:  21906\n",
      "Episode:  21916\n",
      "Episode:  21927\n",
      "Episode:  21936\n",
      "Episode:  21946\n",
      "Episode:  21954\n",
      "Episode:  21964\n",
      "Episode:  21973\n",
      "Episode:  21984\n",
      "Episode:  21994\n",
      "Episode:  22004\n",
      "Episode:  22015\n",
      "Episode:  22027\n",
      "Episode:  22037\n",
      "Episode:  22050\n",
      "Episode:  22062\n",
      "Episode:  22075\n",
      "Episode:  22087\n",
      "Episode:  22099\n",
      "Episode:  22112\n",
      "Episode:  22123\n",
      "Episode:  22136\n",
      "Episode:  22148\n",
      "Episode:  22159\n",
      "Episode:  22171\n",
      "Episode:  22182\n",
      "Episode:  22196\n",
      "Episode:  22208\n",
      "Episode:  22220\n",
      "Episode:  22233\n",
      "Episode:  22246\n",
      "Episode:  22259\n",
      "Episode:  22270\n",
      "Episode:  22284\n",
      "Episode:  22297\n",
      "Episode:  22311\n",
      "Episode:  22324\n",
      "Episode:  22337\n",
      "Episode:  22351\n",
      "Episode:  22363\n",
      "Episode:  22375\n",
      "Episode:  22388\n",
      "Episode:  22403\n",
      "Episode:  22416\n",
      "Episode:  22429\n",
      "Episode:  22442\n",
      "Episode:  22455\n",
      "Episode:  22467\n",
      "Episode:  22479\n",
      "Episode:  22491\n",
      "Episode:  22505\n",
      "Episode:  22517\n",
      "Episode:  22530\n",
      "Episode:  22542\n",
      "Episode:  22554\n",
      "Episode:  22565\n",
      "Episode:  22579\n",
      "Episode:  22591\n",
      "Episode:  22605\n",
      "Episode:  22619\n",
      "Episode:  22632\n",
      "Episode:  22646\n",
      "Episode:  22659\n",
      "Episode:  22671\n",
      "Episode:  22683\n",
      "Episode:  22694\n",
      "Episode:  22706\n",
      "Episode:  22715\n",
      "Episode:  22725\n",
      "Episode:  22737\n",
      "Episode:  22746\n",
      "Episode:  22755\n",
      "Episode:  22764\n",
      "Episode:  22776\n",
      "Episode:  22785\n",
      "Episode:  22795\n",
      "Episode:  22806\n",
      "Episode:  22816\n",
      "Episode:  22825\n",
      "Episode:  22835\n",
      "Episode:  22845\n",
      "Episode:  22854\n",
      "Episode:  22865\n",
      "Episode:  22875\n",
      "Episode:  22886\n",
      "Episode:  22896\n",
      "Episode:  22908\n",
      "Episode:  22922\n",
      "Episode:  22935\n",
      "Episode:  22947\n",
      "Episode:  22959\n",
      "Episode:  22968\n",
      "Episode:  22978\n",
      "Episode:  22987\n",
      "Episode:  22998\n",
      "Episode:  23009\n",
      "Episode:  23018\n",
      "Episode:  23027\n",
      "Episode:  23038\n",
      "Episode:  23048\n",
      "Episode:  23058\n",
      "Episode:  23067\n",
      "Episode:  23075\n",
      "Episode:  23084\n",
      "Episode:  23093\n",
      "Episode:  23104\n",
      "Episode:  23112\n",
      "Episode:  23120\n",
      "Episode:  23128\n",
      "Episode:  23136\n",
      "Episode:  23144\n",
      "Episode:  23152\n",
      "Episode:  23158\n",
      "Episode:  23165\n",
      "Episode:  23173\n",
      "Episode:  23181\n",
      "Episode:  23187\n",
      "Episode:  23195\n",
      "Episode:  23203\n",
      "Episode:  23210\n",
      "Episode:  23218\n",
      "Episode:  23227\n",
      "Episode:  23235\n",
      "Episode:  23242\n",
      "Episode:  23249\n",
      "Episode:  23257\n",
      "Episode:  23266\n",
      "Episode:  23275\n",
      "Episode:  23283\n",
      "Episode:  23292\n",
      "Episode:  23302\n",
      "Episode:  23311\n",
      "Episode:  23321\n",
      "Episode:  23328\n",
      "Episode:  23337\n",
      "Episode:  23345\n",
      "Episode:  23355\n",
      "Episode:  23364\n",
      "Episode:  23373\n",
      "Episode:  23382\n",
      "Episode:  23392\n",
      "Episode:  23400\n",
      "Episode:  23409\n",
      "Episode:  23418\n",
      "Episode:  23426\n",
      "Episode:  23435\n",
      "Episode:  23444\n",
      "Episode:  23452\n",
      "Episode:  23460\n",
      "Episode:  23469\n",
      "Episode:  23475\n",
      "Episode:  23483\n",
      "Episode:  23490\n",
      "Episode:  23499\n",
      "Episode:  23507\n",
      "Episode:  23515\n",
      "Episode:  23523\n",
      "Episode:  23533\n",
      "Episode:  23541\n",
      "Episode:  23550\n",
      "Episode:  23558\n",
      "Episode:  23567\n",
      "Episode:  23576\n",
      "Episode:  23584\n",
      "Episode:  23594\n",
      "Episode:  23605\n",
      "Episode:  23614\n",
      "Episode:  23624\n",
      "Episode:  23632\n",
      "Episode:  23641\n",
      "Episode:  23650\n",
      "Episode:  23658\n",
      "Episode:  23667\n",
      "Episode:  23677\n",
      "Episode:  23687\n",
      "Episode:  23696\n",
      "Episode:  23707\n",
      "Episode:  23717\n",
      "Episode:  23726\n",
      "Episode:  23735\n",
      "Episode:  23745\n",
      "Episode:  23754\n",
      "Episode:  23764\n",
      "Episode:  23774\n",
      "Episode:  23785\n",
      "Episode:  23795\n",
      "Episode:  23806\n",
      "Episode:  23816\n",
      "Episode:  23826\n",
      "Episode:  23836\n",
      "Episode:  23846\n",
      "Episode:  23854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  23863\n",
      "Episode:  23872\n",
      "Episode:  23880\n",
      "Episode:  23887\n",
      "Episode:  23894\n",
      "Episode:  23902\n",
      "Episode:  23908\n",
      "Episode:  23914\n",
      "Episode:  23920\n",
      "Episode:  23926\n",
      "Episode:  23931\n",
      "Episode:  23937\n",
      "Episode:  23943\n",
      "Episode:  23949\n",
      "Episode:  23954\n",
      "Episode:  23960\n",
      "Episode:  23965\n",
      "Episode:  23970\n",
      "Episode:  23976\n",
      "Episode:  23981\n",
      "Episode:  23986\n",
      "Episode:  23992\n",
      "Episode:  23998\n",
      "Episode:  24006\n",
      "Episode:  24012\n",
      "Episode:  24018\n",
      "Episode:  24024\n",
      "Episode:  24030\n",
      "Episode:  24036\n",
      "Episode:  24041\n",
      "Episode:  24046\n",
      "Episode:  24052\n",
      "Episode:  24057\n",
      "Episode:  24062\n",
      "Episode:  24067\n",
      "Episode:  24072\n",
      "Episode:  24077\n",
      "Episode:  24082\n",
      "Episode:  24087\n",
      "Episode:  24092\n",
      "Episode:  24097\n",
      "Episode:  24103\n",
      "Episode:  24108\n",
      "Episode:  24113\n",
      "Episode:  24118\n",
      "Episode:  24123\n",
      "Episode:  24128\n",
      "Episode:  24133\n",
      "Episode:  24138\n",
      "Episode:  24143\n",
      "Episode:  24148\n",
      "Episode:  24153\n",
      "Episode:  24158\n",
      "Episode:  24163\n",
      "Episode:  24168\n",
      "Episode:  24173\n",
      "Episode:  24178\n",
      "Episode:  24183\n",
      "Episode:  24188\n",
      "Episode:  24193\n",
      "Episode:  24198\n",
      "Episode:  24204\n",
      "Episode:  24209\n",
      "Episode:  24214\n",
      "Episode:  24219\n",
      "Episode:  24224\n",
      "Episode:  24229\n",
      "Episode:  24234\n",
      "Episode:  24239\n",
      "Episode:  24244\n",
      "Episode:  24249\n",
      "Episode:  24254\n",
      "Episode:  24259\n",
      "Episode:  24264\n",
      "Episode:  24269\n",
      "Episode:  24274\n",
      "Episode:  24280\n",
      "Episode:  24285\n",
      "Episode:  24290\n",
      "Episode:  24295\n",
      "Episode:  24300\n",
      "Episode:  24306\n",
      "Episode:  24311\n",
      "Episode:  24316\n",
      "Episode:  24321\n",
      "Episode:  24326\n",
      "Episode:  24331\n",
      "Episode:  24336\n",
      "Episode:  24341\n",
      "Episode:  24346\n",
      "Episode:  24351\n",
      "Episode:  24356\n",
      "Episode:  24361\n",
      "Episode:  24366\n",
      "Episode:  24371\n",
      "Episode:  24376\n",
      "Episode:  24381\n",
      "Episode:  24386\n",
      "Episode:  24391\n",
      "Episode:  24396\n",
      "Episode:  24402\n",
      "Episode:  24407\n",
      "Episode:  24412\n",
      "Episode:  24417\n",
      "Episode:  24422\n",
      "Episode:  24427\n",
      "Episode:  24432\n",
      "Episode:  24437\n",
      "Episode:  24442\n",
      "Episode:  24447\n",
      "Episode:  24452\n",
      "Episode:  24457\n",
      "Episode:  24462\n",
      "Episode:  24467\n",
      "Episode:  24472\n",
      "Episode:  24477\n",
      "Episode:  24482\n",
      "Episode:  24487\n",
      "Episode:  24492\n",
      "Episode:  24497\n",
      "Episode:  24503\n",
      "Episode:  24508\n",
      "Episode:  24513\n",
      "Episode:  24518\n",
      "Episode:  24523\n",
      "Episode:  24528\n",
      "Episode:  24533\n",
      "Episode:  24538\n",
      "Episode:  24543\n",
      "Episode:  24548\n",
      "Episode:  24553\n",
      "Episode:  24558\n",
      "Episode:  24563\n",
      "Episode:  24568\n",
      "Episode:  24573\n",
      "Episode:  24578\n",
      "Episode:  24583\n",
      "Episode:  24588\n",
      "Episode:  24593\n",
      "Episode:  24598\n",
      "Episode:  24604\n",
      "Episode:  24609\n",
      "Episode:  24614\n",
      "Episode:  24620\n",
      "Episode:  24625\n",
      "Episode:  24630\n",
      "Episode:  24635\n",
      "Episode:  24640\n",
      "Episode:  24645\n",
      "Episode:  24650\n",
      "Episode:  24655\n",
      "Episode:  24660\n",
      "Episode:  24665\n",
      "Episode:  24670\n",
      "Episode:  24675\n",
      "Episode:  24680\n",
      "Episode:  24685\n",
      "Episode:  24690\n",
      "Episode:  24695\n",
      "Episode:  24700\n",
      "Episode:  24706\n",
      "Episode:  24711\n",
      "Episode:  24716\n",
      "Episode:  24721\n",
      "Episode:  24726\n",
      "Episode:  24731\n",
      "Episode:  24736\n",
      "Episode:  24741\n",
      "Episode:  24746\n",
      "Episode:  24751\n",
      "Episode:  24756\n",
      "Episode:  24761\n",
      "Episode:  24766\n",
      "Episode:  24771\n",
      "Episode:  24776\n",
      "Episode:  24781\n",
      "Episode:  24786\n",
      "Episode:  24791\n",
      "Episode:  24796\n",
      "Episode:  24802\n",
      "Episode:  24807\n",
      "Episode:  24812\n",
      "Episode:  24817\n",
      "Episode:  24823\n",
      "Episode:  24829\n",
      "Episode:  24834\n",
      "Episode:  24839\n",
      "Episode:  24844\n",
      "Episode:  24850\n",
      "Episode:  24855\n",
      "Episode:  24860\n",
      "Episode:  24865\n",
      "Episode:  24870\n",
      "Episode:  24875\n",
      "Episode:  24880\n",
      "Episode:  24885\n",
      "Episode:  24890\n",
      "Episode:  24895\n",
      "Episode:  24900\n",
      "Episode:  24906\n",
      "Episode:  24911\n",
      "Episode:  24916\n",
      "Episode:  24921\n",
      "Episode:  24926\n",
      "Episode:  24931\n",
      "Episode:  24936\n",
      "Episode:  24941\n",
      "Episode:  24946\n",
      "Episode:  24951\n",
      "Episode:  24956\n",
      "Episode:  24961\n",
      "Episode:  24966\n",
      "Episode:  24971\n",
      "Episode:  24976\n",
      "Episode:  24981\n",
      "Episode:  24986\n",
      "Episode:  24991\n",
      "Episode:  24996\n",
      "Episode:  25002\n",
      "Episode:  25007\n",
      "Episode:  25012\n",
      "Episode:  25017\n",
      "Episode:  25022\n",
      "Episode:  25027\n",
      "Episode:  25032\n",
      "Episode:  25037\n",
      "Episode:  25042\n",
      "Episode:  25047\n",
      "Episode:  25052\n",
      "Episode:  25057\n",
      "Episode:  25062\n",
      "Episode:  25067\n",
      "Episode:  25072\n",
      "Episode:  25077\n",
      "Episode:  25082\n",
      "Episode:  25087\n",
      "Episode:  25092\n",
      "Episode:  25097\n",
      "Episode:  25103\n",
      "Episode:  25108\n",
      "Episode:  25113\n",
      "Episode:  25118\n",
      "Episode:  25123\n",
      "Episode:  25128\n",
      "Episode:  25133\n",
      "Episode:  25138\n",
      "Episode:  25143\n",
      "Episode:  25148\n",
      "Episode:  25153\n",
      "Episode:  25158\n",
      "Episode:  25163\n",
      "Episode:  25168\n",
      "Episode:  25173\n",
      "Episode:  25178\n",
      "Episode:  25183\n",
      "Episode:  25188\n",
      "Episode:  25193\n",
      "Episode:  25198\n",
      "Episode:  25204\n",
      "Episode:  25209\n",
      "Episode:  25214\n",
      "Episode:  25219\n",
      "Episode:  25224\n",
      "Episode:  25229\n",
      "Episode:  25234\n",
      "Episode:  25239\n",
      "Episode:  25244\n",
      "Episode:  25249\n",
      "Episode:  25254\n",
      "Episode:  25259\n",
      "Episode:  25264\n",
      "Episode:  25269\n",
      "Episode:  25274\n",
      "Episode:  25279\n",
      "Episode:  25284\n",
      "Episode:  25289\n",
      "Episode:  25294\n",
      "Episode:  25299\n",
      "Episode:  25305\n",
      "Episode:  25310\n",
      "Episode:  25315\n",
      "Episode:  25320\n",
      "Episode:  25325\n",
      "Episode:  25330\n",
      "Episode:  25335\n",
      "Episode:  25340\n",
      "Episode:  25345\n",
      "Episode:  25350\n",
      "Episode:  25355\n",
      "Episode:  25360\n",
      "Episode:  25365\n",
      "Episode:  25370\n",
      "Episode:  25375\n",
      "Episode:  25380\n",
      "Episode:  25385\n",
      "Episode:  25390\n",
      "Episode:  25395\n",
      "Episode:  25400\n",
      "Episode:  25406\n",
      "Episode:  25411\n",
      "Episode:  25416\n",
      "Episode:  25421\n",
      "Episode:  25426\n",
      "Episode:  25431\n",
      "Episode:  25436\n",
      "Episode:  25441\n",
      "Episode:  25446\n",
      "Episode:  25451\n",
      "Episode:  25456\n",
      "Episode:  25461\n",
      "Episode:  25466\n",
      "Episode:  25471\n",
      "Episode:  25476\n",
      "Episode:  25481\n",
      "Episode:  25486\n",
      "Episode:  25491\n",
      "Episode:  25496\n",
      "Episode:  25502\n",
      "Episode:  25508\n",
      "Episode:  25514\n",
      "Episode:  25519\n",
      "Episode:  25524\n",
      "Episode:  25529\n",
      "Episode:  25534\n",
      "Episode:  25539\n",
      "Episode:  25544\n",
      "Episode:  25550\n",
      "Episode:  25555\n",
      "Episode:  25560\n",
      "Episode:  25565\n",
      "Episode:  25570\n",
      "Episode:  25575\n",
      "Episode:  25580\n",
      "Episode:  25586\n",
      "Episode:  25592\n",
      "Episode:  25598\n",
      "Episode:  25605\n",
      "Episode:  25610\n",
      "Episode:  25616\n",
      "Episode:  25622\n",
      "Episode:  25627\n",
      "Episode:  25633\n",
      "Episode:  25639\n",
      "Episode:  25644\n",
      "Episode:  25650\n",
      "Episode:  25656\n",
      "Episode:  25661\n",
      "Episode:  25666\n",
      "Episode:  25671\n",
      "Episode:  25676\n",
      "Episode:  25681\n",
      "Episode:  25686\n",
      "Episode:  25691\n",
      "Episode:  25697\n",
      "Episode:  25703\n",
      "Episode:  25708\n",
      "Episode:  25713\n",
      "Episode:  25719\n",
      "Episode:  25725\n",
      "Episode:  25730\n",
      "Episode:  25735\n",
      "Episode:  25740\n",
      "Episode:  25745\n",
      "Episode:  25750\n",
      "Episode:  25755\n",
      "Episode:  25760\n",
      "Episode:  25765\n",
      "Episode:  25770\n",
      "Episode:  25775\n",
      "Episode:  25780\n",
      "Episode:  25786\n",
      "Episode:  25791\n",
      "Episode:  25796\n",
      "Episode:  25802\n",
      "Episode:  25807\n",
      "Episode:  25812\n",
      "Episode:  25817\n",
      "Episode:  25822\n",
      "Episode:  25827\n",
      "Episode:  25832\n",
      "Episode:  25838\n",
      "Episode:  25844\n",
      "Episode:  25850\n",
      "Episode:  25855\n",
      "Episode:  25860\n",
      "Episode:  25866\n",
      "Episode:  25873\n",
      "Episode:  25879\n",
      "Episode:  25886\n",
      "Episode:  25893\n",
      "Episode:  25899\n",
      "Episode:  25906\n",
      "Episode:  25913\n",
      "Episode:  25920\n",
      "Episode:  25926\n",
      "Episode:  25933\n",
      "Episode:  25940\n",
      "Episode:  25947\n",
      "Episode:  25952\n",
      "Episode:  25957\n",
      "Episode:  25962\n",
      "Episode:  25967\n",
      "Episode:  25972\n",
      "Episode:  25977\n",
      "Episode:  25982\n",
      "Episode:  25987\n",
      "Episode:  25992\n",
      "Episode:  25997\n",
      "Episode:  26003\n",
      "Episode:  26009\n",
      "Episode:  26015\n",
      "Episode:  26022\n",
      "Episode:  26027\n",
      "Episode:  26033\n",
      "Episode:  26038\n",
      "Episode:  26043\n",
      "Episode:  26049\n",
      "Episode:  26054\n",
      "Episode:  26060\n",
      "Episode:  26066\n",
      "Episode:  26071\n",
      "Episode:  26077\n",
      "Episode:  26084\n",
      "Episode:  26090\n",
      "Episode:  26095\n",
      "Episode:  26100\n",
      "Episode:  26106\n",
      "Episode:  26111\n",
      "Episode:  26116\n",
      "Episode:  26121\n",
      "Episode:  26126\n",
      "Episode:  26132\n",
      "Episode:  26138\n",
      "Episode:  26144\n",
      "Episode:  26150\n",
      "Episode:  26156\n",
      "Episode:  26162\n",
      "Episode:  26168\n",
      "Episode:  26175\n",
      "Episode:  26180\n",
      "Episode:  26186\n",
      "Episode:  26191\n",
      "Episode:  26196\n",
      "Episode:  26202\n",
      "Episode:  26208\n",
      "Episode:  26213\n",
      "Episode:  26218\n",
      "Episode:  26223\n",
      "Episode:  26228\n",
      "Episode:  26233\n",
      "Episode:  26238\n",
      "Episode:  26243\n",
      "Episode:  26248\n",
      "Episode:  26253\n",
      "Episode:  26258\n",
      "Episode:  26264\n",
      "Episode:  26271\n",
      "Episode:  26278\n",
      "Episode:  26287\n",
      "Episode:  26295\n",
      "Episode:  26302\n",
      "Episode:  26309\n",
      "Episode:  26315\n",
      "Episode:  26320\n",
      "Episode:  26325\n",
      "Episode:  26331\n",
      "Episode:  26337\n",
      "Episode:  26345\n",
      "Episode:  26351\n",
      "Episode:  26357\n",
      "Episode:  26363\n",
      "Episode:  26369\n",
      "Episode:  26375\n",
      "Episode:  26381\n",
      "Episode:  26387\n",
      "Episode:  26393\n",
      "Episode:  26398\n",
      "Episode:  26404\n",
      "Episode:  26409\n",
      "Episode:  26414\n",
      "Episode:  26419\n",
      "Episode:  26424\n",
      "Episode:  26429\n",
      "Episode:  26434\n",
      "Episode:  26439\n",
      "Episode:  26444\n",
      "Episode:  26449\n",
      "Episode:  26454\n",
      "Episode:  26459\n",
      "Episode:  26464\n",
      "Episode:  26469\n",
      "Episode:  26474\n",
      "Episode:  26479\n",
      "Episode:  26484\n",
      "Episode:  26489\n",
      "Episode:  26495\n",
      "Episode:  26500\n",
      "Episode:  26507\n",
      "Episode:  26513\n",
      "Episode:  26520\n",
      "Episode:  26526\n",
      "Episode:  26532\n",
      "Episode:  26537\n",
      "Episode:  26542\n",
      "Episode:  26547\n",
      "Episode:  26553\n",
      "Episode:  26559\n",
      "Episode:  26564\n",
      "Episode:  26569\n",
      "Episode:  26574\n",
      "Episode:  26579\n",
      "Episode:  26585\n",
      "Episode:  26590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  26595\n",
      "Episode:  26602\n",
      "Episode:  26607\n",
      "Episode:  26613\n",
      "Episode:  26620\n",
      "Episode:  26628\n",
      "Episode:  26635\n",
      "Episode:  26641\n",
      "Episode:  26647\n",
      "Episode:  26654\n",
      "Episode:  26659\n",
      "Episode:  26665\n",
      "Episode:  26670\n",
      "Episode:  26675\n",
      "Episode:  26680\n",
      "Episode:  26686\n",
      "Episode:  26691\n",
      "Episode:  26696\n",
      "Episode:  26702\n",
      "Episode:  26707\n",
      "Episode:  26712\n",
      "Episode:  26717\n",
      "Episode:  26723\n",
      "Episode:  26728\n",
      "Episode:  26733\n",
      "Episode:  26738\n",
      "Episode:  26743\n",
      "Episode:  26748\n",
      "Episode:  26753\n",
      "Episode:  26758\n",
      "Episode:  26763\n",
      "Episode:  26768\n",
      "Episode:  26774\n",
      "Episode:  26779\n",
      "Episode:  26784\n",
      "Episode:  26789\n",
      "Episode:  26794\n",
      "Episode:  26799\n",
      "Episode:  26806\n",
      "Episode:  26812\n",
      "Episode:  26818\n",
      "Episode:  26825\n",
      "Episode:  26831\n",
      "Episode:  26837\n",
      "Episode:  26843\n",
      "Episode:  26848\n",
      "Episode:  26854\n",
      "Episode:  26859\n",
      "Episode:  26864\n",
      "Episode:  26869\n",
      "Episode:  26874\n",
      "Episode:  26879\n",
      "Episode:  26884\n",
      "Episode:  26890\n",
      "Episode:  26895\n",
      "Episode:  26900\n",
      "Episode:  26906\n",
      "Episode:  26911\n",
      "Episode:  26916\n",
      "Episode:  26922\n",
      "Episode:  26928\n",
      "Episode:  26935\n",
      "Episode:  26940\n",
      "Episode:  26945\n",
      "Episode:  26950\n",
      "Episode:  26956\n",
      "Episode:  26962\n",
      "Episode:  26967\n",
      "Episode:  26972\n",
      "Episode:  26977\n",
      "Episode:  26984\n",
      "Episode:  26989\n",
      "Episode:  26994\n",
      "Episode:  26999\n",
      "Episode:  27005\n",
      "Episode:  27010\n",
      "Episode:  27015\n",
      "Episode:  27021\n",
      "Episode:  27028\n",
      "Episode:  27034\n",
      "Episode:  27040\n",
      "Episode:  27045\n",
      "Episode:  27050\n",
      "Episode:  27055\n",
      "Episode:  27060\n",
      "Episode:  27065\n",
      "Episode:  27071\n",
      "Episode:  27076\n",
      "Episode:  27081\n",
      "Episode:  27086\n",
      "Episode:  27091\n",
      "Episode:  27096\n",
      "Episode:  27102\n",
      "Episode:  27107\n",
      "Episode:  27112\n",
      "Episode:  27117\n",
      "Episode:  27122\n",
      "Episode:  27127\n",
      "Episode:  27132\n",
      "Episode:  27137\n",
      "Episode:  27143\n",
      "Episode:  27149\n",
      "Episode:  27156\n",
      "Episode:  27164\n",
      "Episode:  27171\n",
      "Episode:  27177\n",
      "Episode:  27185\n",
      "Episode:  27193\n",
      "Episode:  27200\n",
      "Episode:  27208\n",
      "Episode:  27215\n",
      "Episode:  27222\n",
      "Episode:  27229\n",
      "Episode:  27235\n",
      "Episode:  27241\n",
      "Episode:  27247\n",
      "Episode:  27253\n",
      "Episode:  27259\n",
      "Episode:  27266\n",
      "Episode:  27273\n",
      "Episode:  27279\n",
      "Episode:  27284\n",
      "Episode:  27290\n",
      "Episode:  27295\n",
      "Episode:  27302\n",
      "Episode:  27308\n",
      "Episode:  27313\n",
      "Episode:  27318\n",
      "Episode:  27323\n",
      "Episode:  27329\n",
      "Episode:  27334\n",
      "Episode:  27340\n",
      "Episode:  27345\n",
      "Episode:  27350\n",
      "Episode:  27355\n",
      "Episode:  27360\n",
      "Episode:  27365\n",
      "Episode:  27370\n",
      "Episode:  27375\n",
      "Episode:  27380\n",
      "Episode:  27385\n",
      "Episode:  27390\n",
      "Episode:  27395\n",
      "Episode:  27400\n",
      "Episode:  27406\n",
      "Episode:  27411\n",
      "Episode:  27416\n",
      "Episode:  27421\n",
      "Episode:  27426\n",
      "Episode:  27431\n",
      "Episode:  27437\n",
      "Episode:  27442\n",
      "Episode:  27447\n",
      "Episode:  27452\n",
      "Episode:  27457\n",
      "Episode:  27462\n",
      "Episode:  27467\n",
      "Episode:  27472\n",
      "Episode:  27477\n",
      "Episode:  27482\n",
      "Episode:  27487\n",
      "Episode:  27492\n",
      "Episode:  27497\n",
      "Episode:  27503\n",
      "Episode:  27508\n",
      "Episode:  27513\n",
      "Episode:  27518\n",
      "Episode:  27523\n",
      "Episode:  27528\n",
      "Episode:  27533\n",
      "Episode:  27538\n",
      "Episode:  27543\n",
      "Episode:  27548\n",
      "Episode:  27553\n",
      "Episode:  27558\n",
      "Episode:  27563\n",
      "Episode:  27568\n",
      "Episode:  27573\n",
      "Episode:  27578\n",
      "Episode:  27583\n",
      "Episode:  27588\n",
      "Episode:  27593\n",
      "Episode:  27598\n",
      "Episode:  27604\n",
      "Episode:  27609\n",
      "Episode:  27614\n",
      "Episode:  27619\n",
      "Episode:  27624\n",
      "Episode:  27629\n",
      "Episode:  27634\n",
      "Episode:  27639\n",
      "Episode:  27644\n",
      "Episode:  27649\n",
      "Episode:  27654\n",
      "Episode:  27659\n",
      "Episode:  27664\n",
      "Episode:  27669\n",
      "Episode:  27674\n",
      "Episode:  27679\n",
      "Episode:  27684\n",
      "Episode:  27689\n",
      "Episode:  27694\n",
      "Episode:  27699\n",
      "Episode:  27705\n",
      "Episode:  27710\n",
      "Episode:  27715\n",
      "Episode:  27720\n",
      "Episode:  27725\n",
      "Episode:  27730\n",
      "Episode:  27735\n",
      "Episode:  27740\n",
      "Episode:  27745\n",
      "Episode:  27750\n",
      "Episode:  27755\n",
      "Episode:  27761\n",
      "Episode:  27766\n",
      "Episode:  27771\n",
      "Episode:  27777\n",
      "Episode:  27782\n",
      "Episode:  27788\n",
      "Episode:  27793\n",
      "Episode:  27799\n",
      "Episode:  27805\n",
      "Episode:  27810\n",
      "Episode:  27815\n",
      "Episode:  27820\n",
      "Episode:  27825\n",
      "Episode:  27830\n",
      "Episode:  27835\n",
      "Episode:  27840\n",
      "Episode:  27845\n",
      "Episode:  27850\n",
      "Episode:  27855\n",
      "Episode:  27860\n",
      "Episode:  27865\n",
      "Episode:  27870\n",
      "Episode:  27875\n",
      "Episode:  27880\n",
      "Episode:  27885\n",
      "Episode:  27890\n",
      "Episode:  27895\n",
      "Episode:  27900\n",
      "Episode:  27906\n",
      "Episode:  27911\n",
      "Episode:  27916\n",
      "Episode:  27921\n",
      "Episode:  27926\n",
      "Episode:  27931\n",
      "Episode:  27936\n",
      "Episode:  27941\n",
      "Episode:  27946\n",
      "Episode:  27951\n",
      "Episode:  27956\n",
      "Episode:  27961\n",
      "Episode:  27966\n",
      "Episode:  27971\n",
      "Episode:  27976\n",
      "Episode:  27981\n",
      "Episode:  27986\n",
      "Episode:  27991\n",
      "Episode:  27996\n",
      "Episode:  28002\n",
      "Episode:  28007\n",
      "Episode:  28012\n",
      "Episode:  28017\n",
      "Episode:  28022\n",
      "Episode:  28027\n",
      "Episode:  28032\n",
      "Episode:  28037\n",
      "Episode:  28042\n",
      "Episode:  28047\n",
      "Episode:  28052\n",
      "Episode:  28058\n",
      "Episode:  28063\n",
      "Episode:  28069\n",
      "Episode:  28074\n",
      "Episode:  28080\n",
      "Episode:  28085\n",
      "Episode:  28090\n",
      "Episode:  28095\n",
      "Episode:  28100\n",
      "Episode:  28106\n",
      "Episode:  28111\n",
      "Episode:  28116\n",
      "Episode:  28121\n",
      "Episode:  28126\n",
      "Episode:  28132\n",
      "Episode:  28137\n",
      "Episode:  28142\n",
      "Episode:  28147\n",
      "Episode:  28153\n",
      "Episode:  28159\n",
      "Episode:  28165\n",
      "Episode:  28171\n",
      "Episode:  28177\n",
      "Episode:  28182\n",
      "Episode:  28187\n",
      "Episode:  28192\n",
      "Episode:  28197\n",
      "Episode:  28204\n",
      "Episode:  28209\n",
      "Episode:  28214\n",
      "Episode:  28220\n",
      "Episode:  28226\n",
      "Episode:  28232\n",
      "Episode:  28238\n",
      "Episode:  28243\n",
      "Episode:  28248\n",
      "Episode:  28253\n",
      "Episode:  28258\n",
      "Episode:  28263\n",
      "Episode:  28268\n",
      "Episode:  28273\n",
      "Episode:  28278\n",
      "Episode:  28283\n",
      "Episode:  28288\n",
      "Episode:  28293\n",
      "Episode:  28298\n",
      "Episode:  28304\n",
      "Episode:  28309\n",
      "Episode:  28314\n",
      "Episode:  28320\n",
      "Episode:  28325\n",
      "Episode:  28331\n",
      "Episode:  28337\n",
      "Episode:  28342\n",
      "Episode:  28348\n",
      "Episode:  28353\n",
      "Episode:  28358\n",
      "Episode:  28363\n",
      "Episode:  28369\n",
      "Episode:  28375\n",
      "Episode:  28381\n",
      "Episode:  28387\n",
      "Episode:  28393\n",
      "Episode:  28399\n",
      "Episode:  28406\n",
      "Episode:  28412\n",
      "Episode:  28417\n",
      "Episode:  28423\n",
      "Episode:  28428\n",
      "Episode:  28433\n",
      "Episode:  28438\n",
      "Episode:  28443\n",
      "Episode:  28449\n",
      "Episode:  28454\n",
      "Episode:  28459\n",
      "Episode:  28464\n",
      "Episode:  28469\n",
      "Episode:  28474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7c0f95f27da6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/danilo/Deep-RL-Keras/PPO/ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, env, args, summary_writer)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0madvantage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_prediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;31m# summary_writer.add_scalar('Actor loss', actor_loss.history['loss'][-1], self.gradient_steps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "rewards, actor_losses, critic_losses = algo.train(env, args, summary_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = algo.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "aux_rewards = []\n",
    "for i in range(len(rewards)):\n",
    "    for j in range(len(rewards[i])):\n",
    "        aux_rewards.append(rewards[i][j])\n",
    "    \n",
    "plt.plot(aux_rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.save_weights(\"saved_models/PPO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick algorithm to test\n",
    "if(args.type==\"DDQN\"):\n",
    "    algo = DDQN(action_dim, state_dim, args)\n",
    "elif(args.type==\"A2C\"):\n",
    "    algo = A2C(action_dim, state_dim, args.consecutive_frames)\n",
    "elif(args.type==\"PPO\"):\n",
    "    algo = PPO(action_dim, state_dim, args.consecutive_frames)\n",
    "elif(args.type==\"A3C\"):\n",
    "    algo = A3C(action_dim, state_dim, args.consecutive_frames, is_atari=args.is_atari)\n",
    "elif(args.type==\"DDPG\"):\n",
    "    algo = DDPG(action_dim, state_dim, act_range, args.consecutive_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.load_weights(\"saved_models/PPO_LR_0.0001_actor.h5\", \"saved_models/PPO_LR_0.0001_critic.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset episode\n",
    "num_test_int = 10\n",
    "global_info = []\n",
    "\n",
    "for i in range(num_test_int):\n",
    "    time, cumul_reward, done = 0, 0, False\n",
    "    old_state = env.reset()\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        # Actor picks an action (following the policy)\n",
    "        a = algo.policy_action(old_state)\n",
    "        # Retrieve new state, reward, and whether the state is terminal\n",
    "        new_state, r, done, _ = env.step(a)\n",
    "        # Update current state\n",
    "        old_state = new_state\n",
    "        cumul_reward += r\n",
    "        time += 1\n",
    "        \n",
    "        if done: \n",
    "            global_info.append({\n",
    "                cumul_reward\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
